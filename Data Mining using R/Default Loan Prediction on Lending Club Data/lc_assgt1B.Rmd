---
title: "R Notebook - Getting started with Assignment 1A on the Lending Club case"
author: "sid b"
date: "Sept 12, 2021"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 


```{r}
library(tidyverse)
library(lubridate)
```


The lcData100K.csv file contains a sample of data on 3-year loans  which we will use for this analyses
```{r}

lcdf <- read_csv('K:/MS MIS/Fall 2021/Data Mining/Assignment 1/lcData100K.csv')
```



#Explore the data
```{r}
# Q 2 A i)
#comparing the number of loans based on the loan status
lcdf %>% group_by(loan_status) %>% tally()

# vary by loan grade
table(lcdf$loan_status, lcdf$sub_grade)

subgr<-c('C1','C2','C3','C4','C5','D1','D2','D3','D4','D5','E1','E2','E3','E4','E5','F1','F2','F3','F4','F5','G1','G2','G3','G4','G5')

lcdffil<-lcdf %>% filter(lcdf$sub_grade %in% subgr)
table(lcdffil$loan_status, lcdffil$sub_grade)

#Q 2 a ii)

lcdf %>% group_by(grade) %>% tally()
lcdf %>% group_by(grade) %>% summarise(median(loan_amnt))  
lcdf %>% group_by(grade) %>% summarise(mean(int_rate))
lcdf %>% group_by(grade) %>% summarise(sum(int_rate))


ggplot(lcdf, aes( x = int_rate)) + geom_histogram()
ggplot(lcdf, aes( x = loan_amnt)) + geom_histogram(aes(fill=grade))
ggplot(lcdf, aes( x = loan_amnt)) + geom_histogram(aes(fill=grade)) + facet_wrap(~loan_status)
ggplot(lcdf, aes(x=grade, y=max(loan_amnt))) + 
  geom_bar(stat='identity')

ggplot(lcdf, aes(x=sub_grade, y=ave(loan_amnt))) + 
  geom_bar(stat='identity')

ggplot(lcdf, aes(x=grade, y=min(loan_amnt))) + 
  geom_bar(stat='identity')

ggplot(lcdf, aes(x=grade, y=mean(loan_amnt))) + 
  geom_bar(stat='identity')

ggplot(lcdf, aes(x=grade, y=median(loan_amnt))) + 
  geom_bar(stat='identity')

lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt))

```


Examine actual returns from a loan, and relation with int_rate
(for example, can one expect a 5%/year return from a loan with 5% int_rate?)
```{r}

#do loans return an amount as may be expected from the int_rate ? 
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt) %>% head()

lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt) %>% filter(loan_status=='Charged Off') %>% filter(total_pymnt>funded_amnt) %>%  count()

lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt, issue_d ,last_pymnt_d) %>% filter(loan_status=='Charged Off') %>% filter(total_pymnt>funded_amnt) %>%  head(10)

#Q 2 A iv)
annualRet <- (sum(lcdf$total_pymnt) -sum(lcdf$funded_amnt))*(12/36)

percentAnnRet<-(annualRet/sum(lcdf$funded_amnt))*100


#calculate the annualized percentage return
lcdf$annRet <- ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(12/36)*100
sum(lcdf$annRet)

lcdf$annRet %>% head()
#summarize by grade
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt), avgRet=mean(annRet), stdRet=sd(annRet), minRet=min(annRet), maxRet=max(annRet))

#Where do the negative numbers for minRet come from?
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt, annRet) %>% filter(annRet < 0) %>% head()

#are these all from 'Charged Off' loans?
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt, annRet) %>% filter(annRet < 0) %>% count(loan_status)

```




```{r}

#Q2 a iii)

head(lcdf[, c("last_pymnt_d", "issue_d")])

lcdf$last_pymnt_d<-paste(lcdf$last_pymnt_d, "-01", sep = "")
#     Then convert this character to a date type variable

temp1<-parse_date_time(lcdf$last_pymnt_d,  "myd")
lcdf$last_pymnt_d<-temp1


#Check their format now
head(lcdf[, c("last_pymnt_d", "issue_d")])



x<- as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)/dyears(1)


lcdf$actualTerm <- ifelse(lcdf$loan_status=="Fully Paid", as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)/dyears(1), 3)

#Then, considering this actual term, the actual annual return is
lcdf$actualReturn <- ifelse(lcdf$actualTerm>0, ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(1/lcdf$actualTerm)*100, 0)

#take a look these variables for the first few rows of data 
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt, annRet, actualTerm, actualReturn) %>%  head()
  
lcdf %>% head()
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt, issue_d ,last_pymnt_d,actualTerm,actualReturn) %>% filter(loan_status=='Charged Off') %>% filter(total_pymnt>funded_amnt) %>%  head(10)

```



```{r}


lcdf%>% group_by(loan_status) %>% summarise(  intRate=mean(int_rate), totRet=mean((total_pymnt-funded_amnt)/funded_amnt)  )
# Notice that the totRet on Charged Off loans as negative, so, for every dollar invested, there is a loss (how much?).

#does this vary by loan_type?  Here, we are expressing totRet as a % value
lcdf%>% group_by(loan_status, grade) %>% summarise(  intRate=mean(int_rate), totRet=mean((total_pymnt-funded_amnt)/funded_amnt)*100 )
     #Is this in line with what you'd expect (from loan grade info)?


#This summary can also help understand:
lcdf%>% group_by(loan_status) %>% summarise(  intRate=mean(int_rate), totRet=mean((total_pymnt-funded_amnt)/funded_amnt), avgActRet=mean(actualReturn)  )


#you may like to look at some of these variables
lcdf %>% select(loan_status, loan_amnt, funded_amnt, total_pymnt, int_rate, actualTerm, actualReturn ) %>% view()

#some more summaries
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgRet=mean(annRet), avgActualRet=mean(actualReturn)*100, avgActualTerm=mean(actualTerm),  minActualRet=min(actualReturn)*100, maxActualRet=max(actualReturn)*100)

lcdf %>% group_by(loan_status) %>% summarise(nLoans=n(), avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgRet=mean(annRet), avgActualRet=mean(actualReturn)*100, avgActualTerm=mean(actualTerm),  minActualRet=min(actualReturn)*100, maxActualRet=max(actualReturn)*100)


```





```{r}

#Q2 A vi)
#what are the different values, and how many examples are there for each value
lcdf %>% group_by(emp_length) %>% tally()

#convert emp_length to factor -- with factor levels ordered in a meaningful way
lcdf$emp_length <- factor(lcdf$emp_length, levels=c("n/a", "< 1 year","1 year","2 years", "3 years" ,  "4 years",   "5 years",   "6 years",   "7 years" ,  "8 years", "9 years", "10+ years" ))


#Do defaults vary by emp_length?
table(lcdf$loan_status, lcdf$emp_length)
  #this shows nujmber of Charged Off and Full Paid loans for different emp_length
#Can we calculate the proportion of Ca=harged Off loans for weach level of emp_length?
cc=table(lcdf$loan_status, lcdf$emp_length)
cc[1,]/(cc[1,] + cc[2,])   #dividing each element of the first row in cc by the sum of first and second row elements.


#Does the loan-grade assigned by LC vary by emp_length?
table(lcdf$grade, lcdf$emp_length)


#some addl summary by emp_length
lcdf %>% group_by(emp_length) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgIntRate=mean(int_rate),  avgLoanAmt=mean(loan_amnt),  avgActRet = mean(actualReturn), avgActTerm=mean(actualTerm))

```



```{r}
#Q 2 a v)
# Does default rate, int-rate, etc vary by loan purpose
lcdf %>% group_by(purpose) %>% tally()
lcdf %>% group_by(purpose) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgIntRate=mean(int_rate),  avgLoanAmt=mean(loan_amnt),  avgActRet = mean(actualReturn), avgActTerm=mean(actualTerm))

#Does loan-grade vary by purpose?
table(lcdf$purpose, lcdf$grade)


#some other detailed analyses
#Does loan purpose relate to emp_length?
table(lcdf$purpose, lcdf$emp_length)

#do those with home-improvement loans own or rent a home?
table(lcdf$home_ownership, lcdf$purpose)



lcdf %>% group_by(purpose) %>% tally()
#some of category levels have very few examples 
#    do you want to recode such categories with very few cases to "other"
lcdf$purpose <- fct_recode(lcdf$purpose, other="wedding", other="educational", other="renewable_energy")


#Plot of loan amount by purpose
boxplot(lcdf$loan_amnt ~ lcdf$purpose)

```




Some derived attributes
```{r}

#2A vii)
#Derived attribute: proportion of satisfactory bankcard accounts 
lcdf$propSatisBankcardAccts <- ifelse(lcdf$num_bc_tl>0, lcdf$num_bc_sats/lcdf$num_bc_tl, 0)
 
#Another one - lets calculate the length of borrower's history with LC
#  i.e time between earliest_cr_line and issue_d
#  Look at these variables - you will notice that earliest_cr_line is read in as 'chr', we first convert it to date
#      and then subtract the two dates
lcdf$earliest_cr_line<-paste(lcdf$earliest_cr_line, "-01", sep = "")
lcdf$earliest_cr_line<-parse_date_time(lcdf$earliest_cr_line, "myd")

#lcdf$issue_d<-parse_date_time(lcdf$issue_d, "myd") <<---we should not do this, since issue_d is already a date type variable
 
# we can use the lubridate functions to precisely handle date-times durations
lcdf$borrHistory <- as.duration(lcdf$earliest_cr_line %--% lcdf$issue_d  ) / dyears(1)


#Another new attribute: ratio of openAccounts to totalAccounts
#lcdf$openAccRatio <- 



#does LC-assigned loan grade vary by borrHistory?
lcdf %>% group_by(grade) %>% summarise(avgBorrHist=mean(borrHistory))


#some additional analyses.......(your own)

```


Converting character variables
```{r}
#Take a look at the variables in the data-set -- are there any variable type changes you want to consider?
glimpse(lcdf)

#  notice that there are a few character type variables - grade, sub_grade, verification_status,....
#   We can  convert all of these to factor
lcdf <- lcdf %>% mutate_if(is.character, as.factor)

```




Drop some variables for potential leakage, others
```{r}

#Drop some other columns which are not useful and those which will cause 'leakage'
lcdf <- lcdf %>% select(-c(funded_amnt_inv, term, emp_title, pymnt_plan, title, zip_code, addr_state, out_prncp, out_prncp_inv, total_pymnt_inv, total_rec_prncp, total_rec_int,total_rec_late_fee,recoveries, collection_recovery_fee, last_credit_pull_d, policy_code, disbursement_method, debt_settlement_flag, hardship_flag, hardship_dpd, settlement_term, application_type))


#Another way -- suppose you want to drop some other variables we will not use in following analyses
varsToRemove <- c("last_pymnt_d", "last_pymnt_amnt","annRet")
lcdf <- lcdf %>% select(-varsToRemove)
  
dim(lcdf)
```





```{r}
#Q 2 c
#Drop variables with all empty values
lcdf <- lcdf %>% select_if(function(x){!all(is.na(x))})
 # How many variables were dropped ?  You can check by dim(lcdf), before and after this command 

dim(lcdf)
#Of the columns remaining, names of columns with missing values
names(lcdf)[colSums(is.na(lcdf))>0]

#missing value proportions in each column
colMeans(is.na(lcdf))
# or, get only those columns where there are missing values
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]


#Are there same number of missing values in a set of attributes, and might there be a reason for this?
#How does this inform your handling of missing values?


#Consider open_acc_6m, which has 97% missing
summary(as.factor(lcdf$open_acc_6m))    # shows the counts by different values of the variable
table(lcdf$open_acc_6m)  #gives the same output  -- but it does not show the NAs
# We can replace missing values in a variable with
#      replace_na( variable, "value for missing")     
table( replace_na( lcdf$open_acc_6m, "missing") )   # shows the 'missing' values
table( lcdf$loan_status, replace_na( lcdf$open_acc_6m, "missing") ) # shows counts by loan_status at different values of the variable

#to get a bar-plot of these
cc<-table( lcdf$loan_status, replace_na( lcdf$open_acc_6m, "missing") )
barplot(cc, col=c("darkblue","red"),legend = rownames(cc))  # here, one bar dominates others
# For a better display, we can get proportion of ChargedOff as cc[1,]/(cc[2,]+cc[1,]).  Then to plot this..
barplot(cc[1,]/(cc[2,]+cc[1,]), legend = rownames(cc), ylab = "prop ChargedOff", main="Prop ChargedOff by open_acc_6m")
```


```{r}
#Consider the "mths_since_" variables -- what do they represent (see data dictionary.
# Are the missing values here due to zeros; or due to no known values in the period considered (then the actual value would be larger than the max value)? Or are are they really unknown?

#  Variable mths_since_last_record has more than 80% values missing
table( lcdf$loan_status, replace_na( lcdf$mths_since_last_record, "missing") )
cc[1,]/(cc[2,]+cc[1,])
# Is the proportion of defaults for 'missing' similar to the large/small values of the variable?  If they do not relate well to larger values, than we should not assume that missings are for values higher than the max.
#If a very large proportion of values is really unknown, may be better to not include this variable in a model?



#For mths_since_last_delinq, which has around 50% values missing 
cc<-table( lcdf$loan_status, replace_na( lcdf$mths_since_last_delinq, "missing") )
cc
cc[1,]/(cc[2,]+cc[1,])
   #Here, is there a pattern of higher defaults for examples which have more recent delinquencies?  If so, we should try to retain this variable, and find a way to reasonably handle the missing values.
```


```{r}
#For mths_since_recent_inq, which has around 10% values missing
cc<-table( lcdf$loan_status, replace_na( lcdf$mths_since_recent_inq, "missing") )
cc[1,]/(cc[2,]+cc[1,])
    # Here,the proportion of defaults for missing values seem similar to the larger values of the variable -- so, may be replace the missings with a large value ?



dim(lcdf)
#Suppose you decide to remove variables which have more than 60% missing values
nm<-names(lcdf)[colMeans(is.na(lcdf))>0.6]
lcdf <- lcdf %>% select(-nm)
dim(lcdf)
```


```{r}
#Impute missing values for remaining variables which have missing values
# - first get the columns with missing values
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]

#summary of data in these columns
nm<- names(lcdf)[colSums(is.na(lcdf))>0]
summary(lcdf[, nm])
```


```{r}
# Q 2c)
lcx<-lcdf[, c(nm)]
lcx<- lcx %>% replace_na(list(bc_open_to_buy=median(lcx$bc_open_to_buy, na.rm=TRUE)))


#Similarly for the other variables
#After trying this out on the temporary dataframe lcx, if we are sure this is what we want, we can now  replace the missing values on the lcdf dataset

lcdf<- lcdf %>% replace_na(list(mths_since_last_delinq=-500, bc_open_to_buy=median(lcdf$bc_open_to_buy, na.rm=TRUE), mo_sin_old_il_acct=1000, mths_since_recent_bc=1000, mths_since_recent_inq=50, num_tl_120dpd_2m = median(lcdf$num_tl_120dpd_2m, na.rm=TRUE),percent_bc_gt_75 = median(lcdf$percent_bc_gt_75, na.rm=TRUE), bc_util=median(lcdf$bc_util, na.rm=TRUE) ))
  # Check that the replacement values for missings are reasonable - we should be able to explain why we are doing this.


#Have this addressed all missing values?
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]
  # we did not replace missings for all attributes - will this be ok for DT based models which we will develop in the next phase?

```

```{r}
#Q 4)
library(pROC) #this package has a function auc(..) which we can readily use

#We will use the function auc(response, prediction) which returns the AUC value for the specified predictor variable, and considering the response variable as the dependent. 
#   Make sure you understand how this works.

# For example:
auc(response=lcdf$loan_status, lcdf$loan_amnt)
 # returns the auc value for loan_amt as the single predictor

#In the auc(..) function, the predictor variable has to be numeric  - otherwise, how would it calculate the AUC (think about how auc is calculated). 
# For a factor variable, we can consider the factor levels as numbers:
auc(response=lcdf$loan_status, as.numeric(lcdf$emp_length))

#Trying this
lcdf$loan_status <- factor(lcdf$loan_status, levels=c("Fully Paid", "Charged Off"))
auc(response=lcdf$loan_status, as.numeric(lcdf$grade))
```


```{r}
# There may be a few date type variables in the data - we will ignore these here.  
# (Data variables can be handled by converting to days-since variables) 



#How would you calculate AUC this for all variables in the dataset?
# Rather than call the function individually for each variable, we can use the sapply(..) function.
#  - look up how the sapply function works.  Similar to the apply() function.


# For the numeric variables:
aucsNum<-sapply(lcdf %>% select_if(is.numeric), auc, response=lcdf$loan_status)
  #Please make sure we understand what is happening here.  How does sapply work?


#Or considering both numeric and factor variables:
aucAll<- sapply(lcdf %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric), auc, response=lcdf$loan_status) 
#aucAll<- sapply(lcdf %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric), pROC::auc, response=lcdf$loan_status)



#TO determine which variables have auc > 0.5
aucAll[aucAll>0.5]
```


```{r}
#Or, we can use the tidy(..) function from the broom package - which converts the 'messy' output into a tidy form as a tibble
library(broom)


tidy(aucAll[aucAll > 0.5]) %>% view()

# or  in any range of values like, tidy(aucAll[aucAll >=0.5 & aucAll < 0.6])
# or in sorted order
variablesInDF<-tidy(aucAll) %>% arrange(desc(aucAll))

# calculating correlation to find potential leackage
cor(lcdf %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric))


```

```{r}
library(xlsx)
write.xlsx (x = as.data.frame(variablesInDF), file = "foo.xlsx")

dim(lcdf)

#Dropping some variable as they have data leakage issue
varsToRemove <- c("total_pymnt","grade","acc_open_past_24mths","bc_open_to_buy","mo_sin_rcnt_tl","funded_amnt","installment","initial_list_status","issue_d","earliest_cr_line","revol_util","pct_tl_nvr_dlq")
lcdf <- lcdf %>% select(-varsToRemove)
lcdf <- lcdf %>% select(-num_rev_accts)

dim(lcdf)

lcdf<-lcdf %>% filter(!is.na(lcdf$avg_cur_bal))

variablesInModel<-colnames(lcdf)

write.xlsx (x = as.data.frame(variablesInModel), file = "varInModel.xlsx")

lcdf <- lcdf %>% mutate(home_ownership=as.factor(home_ownership),verification_status=as.factor(verification_status))
```



Next we will build some models


Split the data into trn, text subsets
```{r}
#Q 5 a)
TRNPROP = 0.7  #proportion of examples in the training sample

nr<-nrow(lcdf)
trnIndex<- sample(1:nr, size = round(TRNPROP * nr), replace=FALSE)

lcdfTrn <- lcdf[trnIndex, ]
lcdfTst <- lcdf[-trnIndex, ]

```


```{r}
# we omited variables with leackage 
glimpse(lcdf)

varsOmit <- c('actualReturn',"actualTerm")  #are there others?

str(lcdfTrn)

```

DT models using rpart

```{r}
library(rpart)

```

```{r}
# Q5 b)
#cp value 0.0001
lcDT1 <- rpart(loan_status ~., data=lcdfTrn %>% select(-varsOmit), method="class", parms = list(split = "information"), control = rpart.control(cp=0.0001, minsplit = 50))

#cp value 0.0003
lcDT2 <- rpart(loan_status ~., data=lcdfTrn %>% select(-varsOmit), method="class", parms = list(split = "information"), control = rpart.control(cp=0.0003, minsplit = 50))

#Evaluate performance
predTrn=predict(lcDT1,lcdfTrn, type='class')
table(pred = predTrn, true=lcdfTrn$loan_status)
mean(predTrn == lcdfTrn$loan_status)
table(pred = predict(lcDT1,lcdfTst, type='class'), true=lcdfTst$loan_status)
mean(predict(lcDT1,lcdfTst, type='class') ==lcdfTst$loan_status)

printcp(lcDT1)
summary(lcDT1)
plotcp(lcDT1)

```


```{r}
#pruning the tree
lcDT1p<- prune.rpart(lcDT1, cp=0.00012)
mean(predict(lcDT1p,lcdfTst, type='class') ==lcdfTst$loan_status)

confusionMatrix(predict(lcDT1p,lcdfTst, type='class'), lcdfTst$loan_status,positive="Charged Off")
```

```{r}
#With a different classsification threshold
CTHRESH=0.3
predProbTrn=predict(lcDT1,lcdfTrn, type='prob')
predTrnCT = ifelse(predProbTrn[, 'Charged Off'] > CTHRESH, 'Charged Off', 'Fully Paid')

table(predictions=factor(predTrnCT, levels=c("Fully Paid", "Charged Off")), actuals=lcdfTrn$loan_status)

```


```{r}
#Q5 c)

library(caret)
library(e1071)

confusionMatrix(predTrn, lcdfTrn$loan_status, positive="Charged Off")


#ROC plot
library(ROCR)

score=predict(lcDT1,lcdfTst, type="prob")[,"Charged Off"]
pred=prediction(score, lcdfTst$loan_status, label.ordering = c("Fully Paid", "Charged Off"))
    #label.ordering here specifies the 'negative', 'positive' class labels   

#ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf)
abline(a=0, b= 1)

#AUC value
aucPerf=performance(pred, "auc")
aucPerf@y.values


#Lift curve
liftPerf <-performance(pred, "lift", "rpp")
plot(liftPerf)

```


```{r}
library(rpart.plot)
rpart.plot::prp(lcDT1, type=2, extra=1)

```



```{r}
library(C50)

# C5.0(OUTCOME ~ ., data=mdTrn, control=C5.0Control(minCases=10))

lcdf_Trn_c50<-C5.0(loan_status ~ ., data=lcdfTrn %>% select(-varsOmit), control=C5.0Control(minCases=10,CF=0.4))


summary(lcdf_Trn_c50)

predTrn <- predict(lcdf_Trn_c50,lcdfTrn)

confusionMatrix(predTrn, lcdfTrn$loan_status, positive="Charged Off")

predTst <- predict(lcdf_Trn_c50,lcdfTst)

confusionMatrix(predTst, lcdfTst$loan_status, positive="Charged Off")

```

```{r}

score=predict(lcdf_Trn_c50,lcdfTst, type="prob")[,"Charged Off"]
pred=prediction(score, lcdfTst$loan_status, label.ordering = c("Fully Paid", "Charged Off"))
    #label.ordering here specifies the 'negative', 'positive' class labels   

#ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf)
abline(a=0, b= 1)

#AUC value
aucPerf=performance(pred, "auc")
aucPerf@y.values


#Lift curve
liftPerf <-performance(pred, "lift", "rpp")
plot(liftPerf)

C5imp(lcdf_Trn_c50, metric = "usage",pct=TRUE) %>% head(10)

```
```{r}
#Q 5 c) Comparing Rpart and C50
score=predict(lcDT1,lcdfTst, type="prob")[,"Charged Off"]
pred=prediction(score, lcdfTst$loan_status, label.ordering = c("Fully Paid", "Charged Off"))
    #label.ordering here specifies the 'negative', 'positive' class labels   

#ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf,main="RPART and C50 ROC Curve", col='red')

#AUC value
aucPerf=performance(pred, "auc")
aucPerf@y.values

score=predict(lcdf_Trn_c50,lcdfTst, type="prob")[,"Charged Off"]
pred=prediction(score, lcdfTst$loan_status, label.ordering = c("Fully Paid", "Charged Off"))
    #label.ordering here specifies the 'negative', 'positive' class labels   

#ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf,main="RPART and C50 ROC Curve", col='green', add=TRUE)
abline(a=0, b= 1)

#AUC value
aucPerf=performance(pred, "auc")
aucPerf@y.values

legend("bottomright", legend=c("RPART ROC", "C50 ROC"), col=c("red","green"), lty=1, cex=0.8)

```

```{r}
#Q6 
library(ranger)

rgModel1 <- ranger(loan_status ~., data=lcdfTrn %>% select(-varsOmit),
num.trees =20, importance='permutation', probability = TRUE)

rgModel2 <- ranger(loan_status ~., data=lcdfTrn %>% select(-varsOmit),
num.trees =100, importance='permutation', probability = TRUE)

rgModel3 <- ranger(loan_status ~., data=lcdfTrn %>% select(-varsOmit),
num.trees =200, importance='permutation', probability = TRUE)

rgModel4 <- ranger(loan_status ~., data=lcdfTrn %>% select(-varsOmit),
num.trees =250, importance='permutation', probability = TRUE)

# checking variable importance for different models
print("RF 20")
importance(rgModel1) %>% tidy() %>%arrange(desc(x)) %>%  head(5)

print("RF 100")
importance(rgModel2)%>% tidy() %>%arrange(desc(x)) %>%  head(5)

print("RF 200")
importance(rgModel3)%>% tidy() %>%arrange(desc(x)) %>%  head(5)

print("RF 250")
importance(rgModel4)%>% tidy() %>%arrange(desc(x)) %>%  head(5)

#scoreTst <- predict(rgModel1,lcdfTst)

```


```{r}
#Q 7 a)
# Comparing different Random Forest models for accuracy on test and train
print("RF Trees=20")

print("Training Data")
scores=predict(rgModel1, lcdfTrn,type="response")$predictions 
scores<-scores[,2]
predData = ifelse(scores >= 0.5, "Charged Off", "Fully Paid") 
predData <- as.factor(predData)
confusionMatrix(predData, lcdfTrn$loan_status)

print("Testing Data")
scores=predict(rgModel1, lcdfTst,type="response")$predictions 
scores<-scores[,2]

predData = ifelse(scores >= 0.5, "Charged Off", "Fully Paid") 
predData <- as.factor(predData)
confusionMatrix(predData, lcdfTst$loan_status)


print("RF Trees=100")

print("Training Data")
scores=predict(rgModel2, lcdfTrn,type="response")$predictions 
scores<-scores[,2]
predData = ifelse(scores >= 0.5, "Charged Off", "Fully Paid") 
predData <- as.factor(predData)
confusionMatrix(predData, lcdfTrn$loan_status)

print("Testing Data")
scores=predict(rgModel2, lcdfTst,type="response")$predictions 
scores<-scores[,2]

predData = ifelse(scores >= 0.5, "Charged Off", "Fully Paid") 
predData <- as.factor(predData)
confusionMatrix(predData, lcdfTst$loan_status)

print("RF Trees=200")

print("Training Data")
scores=predict(rgModel3, lcdfTrn,type="response")$predictions 
scores<-scores[,2]
predData = ifelse(scores >= 0.5, "Charged Off", "Fully Paid") 
predData <- as.factor(predData)
confusionMatrix(predData, lcdfTrn$loan_status)

print("Testing Data")
scores=predict(rgModel3, lcdfTst,type="response")$predictions 
scores<-scores[,2]

predData = ifelse(scores >= 0.5, "Charged Off", "Fully Paid") 
predData <- as.factor(predData)
confusionMatrix(predData, lcdfTst$loan_status)

print("RF Trees=250")

print("Training Data")
scores=predict(rgModel4, lcdfTrn,type="response")$predictions 
scores<-scores[,2]
predData = ifelse(scores >= 0.5, "Charged Off", "Fully Paid") 
predData <- as.factor(predData)
confusionMatrix(predData, lcdfTrn$loan_status)

print("Testing Data")
scores=predict(rgModel4, lcdfTst,type="response")$predictions 
scores<-scores[,2]

predData = ifelse(scores >= 0.5, "Charged Off", "Fully Paid") 
predData <- as.factor(predData)
confusionMatrix(predData, lcdfTst$loan_status)
```


```{r}
#ROC plot
library(ROCR)

# comparing random forst and decision tree
perfROC_rfRangerTrn=performance(prediction(predict(rgModel1,lcdfTrn)$predictions[,2], lcdfTrn$loan_status, label.ordering=c("Fully Paid","Charged Off")), "tpr", "fpr")
plot(perfROC_rfRangerTrn, main="Ranger Random Forest ROC Curve", col='red')


pred_rfRangerTst=predict(rgModel1,lcdfTst)$predictions 
perfROC_rfRangerTst=performance(prediction(predict(rgModel1,lcdfTst)$predictions[,2], lcdfTst$loan_status, label.ordering=c("Fully Paid","Charged Off")), "tpr", "fpr")

plot(perfROC_rfRangerTst, main="Ranger Random Forest ROC Curve", col='blue', add=TRUE)


pred_rfRangerTst2=predict(rgModel2,lcdfTst)$predictions 
perfROC_rfRangerTst2=performance(prediction(predict(rgModel2,lcdfTst)$predictions[,2], lcdfTst$loan_status, label.ordering=c("Fully Paid","Charged Off")), "tpr", "fpr")
plot(perfROC_rfRangerTst2, main="Ranger Random Forest ROC Curve", col='green', add=TRUE)



score=predict(lcDT1,lcdfTst, type="prob")[,"Charged Off"]
pred=prediction(score, lcdfTst$loan_status, label.ordering = c("Fully Paid", "Charged Off"))
    #label.ordering here specifies the 'negative', 'positive' class labels   
#ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf,main="Ranger Random Forest ROC Curve", col='pink', add=TRUE)

score=predict(lcdf_Trn_c50,lcdfTst, type="prob")[,"Charged Off"]
pred=prediction(score, lcdfTst$loan_status, label.ordering = c("Fully Paid", "Charged Off"))
    #label.ordering here specifies the 'negative', 'positive' class labels   

#ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf,main="RPART and C50 ROC Curve", col='orange', add=TRUE)

legend("bottomright", legend=c("RF Training Data", "RF200 Test Data","RF100 Test Data","Rpart DT","C50"), col=c("red", "blue","green","pink","orange"), lty=1, cex=0.8)
abline(a=0, b= 1)

```
```{r}

# Comparing random forest with c50
perfROC_rfRangerTrn=performance(prediction(predict(rgModel3,lcdfTrn)$predictions[,2], lcdfTrn$loan_status, label.ordering=c("Fully Paid","Charged Off")), "tpr", "fpr")
plot(perfROC_rfRangerTrn, main="Random forest and C50 ROC Curve", col='red')



pred_rfRangerTst=predict(rgModel3,lcdfTst)$predictions 
perfROC_rfRangerTst=performance(prediction(predict(rgModel3,lcdfTst)$predictions[,2], lcdfTst$loan_status, label.ordering=c("Fully Paid","Charged Off")), "tpr", "fpr")

plot(perfROC_rfRangerTst, main="Random forest and C50 ROC Curve", col='blue', add=TRUE)

aucPerf=performance(prediction(predict(rgModel3,lcdfTst)$predictions[,2], lcdfTst$loan_status, label.ordering=c("Fully Paid","Charged Off")), "auc")
aucPerf@y.values

score=predict(lcdf_Trn_c50,lcdfTst, type="prob")[,"Charged Off"]
pred=prediction(score, lcdfTst$loan_status, label.ordering = c("Fully Paid", "Charged Off"))
    #label.ordering here specifies the 'negative', 'positive' class labels   

#ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf,main="Random forest and C50 ROC Curve", col='green', add=TRUE)


legend("bottomright", legend=c("RF200 Training Data","RF200 Test Data","C50"), col=c("red", "blue","green"), lty=1, cex=0.8)
abline(a=0, b= 1)

```
```{r}
aucPerf=performance(prediction(predict(rgModel3,lcdfTst)$predictions[,2], lcdfTst$loan_status, label.ordering=c("Fully Paid","Charged Off")), "auc")
aucPerf@y.values

liftPerf <-performance(prediction(predict(rgModel3,lcdfTst)$predictions[,2], lcdfTst$loan_status, label.ordering=c("Fully Paid","Charged Off")), "lift", "rpp")
plot(liftPerf)


```


```{r}
```

```{r}
#Question 7a

#Random Forest
print("Training Data")
scores=predict(rgModel3, lcdfTrn,type="response")$predictions 
scores<-scores[,2]
predData = ifelse(scores >= 0.8, "Charged Off", "Fully Paid") 
predData <- as.factor(predData)
confusionMatrix(predData, lcdfTrn$loan_status)

print("Testing Data")
scores=predict(rgModel3, lcdfTst,type="response")$predictions 
scores<-scores[,2]

predData = ifelse(scores >= 0.8, "Charged Off", "Fully Paid") 
predData <- as.factor(predData)
confusionMatrix(predData, lcdfTst$loan_status)


#C50
print("Training Data")

scores=predict(lcdf_Trn_c50,lcdfTrn, type="prob")[,"Charged Off"]
predData = ifelse(scores >= 0.8, "Charged Off", "Fully Paid") 
predData <- as.factor(predData)

confusionMatrix(predData, lcdfTrn$loan_status, positive="Charged Off")


print("Testing Data")

scores=predict(lcdf_Trn_c50,lcdfTst, type="prob")[,"Charged Off"]
predData = ifelse(scores >= 0.8, "Charged Off", "Fully Paid") 
predData <- as.factor(predData)

confusionMatrix(predData, lcdfTst$loan_status, positive="Charged Off")


```

```{r}
#Question 7b
lcdf %>% group_by(loan_status) %>% summarise(avgInt=mean(int_rate),avgActInt = mean(actualReturn))

lcdf %>% group_by(loan_status) %>% summarise(avgInt=mean(int_rate), avgRet=mean(actualReturn),
avgTerm=mean(actualTerm))
```

```{r}
PROFITVAL <- 24
COSTVAL <- -35

scoreTstRF <- predict(lcdf_Trn_c50, lcdfTst, type="prob")[,"Fully Paid"]
prPerfRF <- data.frame(scoreTstRF)
prPerfRF <- cbind(prPerfRF, status=lcdfTst$loan_status)
prPerfRF <- prPerfRF[order(-scoreTstRF) ,] #sort in desc order of prob(fully_paid)
prPerfRF$profit <- ifelse(prPerfRF$status == 'Fully Paid', PROFITVAL, COSTVAL)
prPerfRF$cumProfit <- cumsum(prPerfRF$profit)
print("Max Profit by c50 Model")
max(prPerfRF$cumProfit)
print("Achieved by concentrating these many top rows")
which.max(prPerfRF$cumProfit)

print("Cutoff=")
print(100*which.max(prPerfRF$cumProfit)/nrow(lcdfTst))

plot(prPerfRF$cumProfit, col='blue',main="C50 Decision 
Tree Profit/Cost")
```
```{r}

scoreTstRF <- predict(rgModel3, lcdfTst,type="response")$predictions
scoreTstRF<-scoreTstRF[,1]
prPerfRF <- data.frame(scoreTstRF)
prPerfRF <- cbind(prPerfRF, status=lcdfTst$loan_status)
prPerfRF <- prPerfRF[order(-scoreTstRF) ,] #sort in desc order of prob(fully_paid)
prPerfRF$profit <- ifelse(prPerfRF$status == 'Fully Paid', PROFITVAL, COSTVAL)
prPerfRF$cumProfit <- cumsum(prPerfRF$profit)
print("Max Profit by Random Forest Model")
max(prPerfRF$cumProfit)
print("Achieved by concentrating these many top rows")
which.max(prPerfRF$cumProfit)

print("Cutoff=")
print(100*which.max(prPerfRF$cumProfit)/nrow(lcdfTst))

plot(prPerfRF$cumProfit, col='blue',main="Random Forest Profit/Cost")
```



```{r}


```


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
